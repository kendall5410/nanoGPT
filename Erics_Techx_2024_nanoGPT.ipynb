{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6Pw4XdZrT0jFaH7FTTM/T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kendall5410/nanoGPT/blob/main/Erics_Techx_2024_nanoGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEFdjm0bm6od",
        "outputId": "7aaf736f-03fa-429b-d2ad-bf03bca4d6de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Tech exchange\n"
          ]
        }
      ],
      "source": [
        "print(\"Hello Tech exchange\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "get the data\n"
      ],
      "metadata": {
        "id": "vUPCsdjMogwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://gir.fyi/techx/input.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xKOB1fsoxPC",
        "outputId": "8976813c-8b55-48ac-964f-b61db4b3f9cd"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-16 16:16:21--  http://gir.fyi/techx/input.txt\n",
            "Resolving gir.fyi (gir.fyi)... 216.239.32.21, 216.239.36.21, 216.239.38.21, ...\n",
            "Connecting to gir.fyi (gir.fyi)|216.239.32.21|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt [following]\n",
            "--2024-05-16 16:16:21--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt.2’\n",
            "\n",
            "input.txt.2         100%[===================>]   1.06M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-05-16 16:16:21 (105 MB/s) - ‘input.txt.2’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('input.txt','r', encoding='utf-8') as f:\n",
        "  raw_training_data = f.read()\n",
        "print(len(raw_training_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjvuoB8Ho35Q",
        "outputId": "ec7e17e9-e4b1-4759-be8f-fbda3997fe85"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1115394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(set(raw_training_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjedM_c9pPvB",
        "outputId": "06241deb-aa09-42e3-fee0-bf9a84912323"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''.join(sorted(set(raw_training_data)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "52-QHIKEpg9M",
        "outputId": "49c73908-f588-4878-d03a-17fbe3711ba9"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "freqs = defaultdict(int)\n",
        "\n",
        "for letter in raw_training_data:\n",
        "  freqs[letter] += 1\n",
        "\n",
        "freqs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bJuYxkCp2Re",
        "outputId": "8cce6c19-0a8d-40be-8414-f33a0e44b703"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(int,\n",
              "            {'F': 1797,\n",
              "             'i': 45537,\n",
              "             'r': 48889,\n",
              "             's': 49696,\n",
              "             't': 67009,\n",
              "             ' ': 169892,\n",
              "             'C': 3820,\n",
              "             'z': 356,\n",
              "             'e': 94611,\n",
              "             'n': 48529,\n",
              "             ':': 10316,\n",
              "             '\\n': 40000,\n",
              "             'B': 2761,\n",
              "             'f': 15770,\n",
              "             'o': 65798,\n",
              "             'w': 17585,\n",
              "             'p': 10808,\n",
              "             'c': 15623,\n",
              "             'd': 31358,\n",
              "             'a': 55507,\n",
              "             'y': 20448,\n",
              "             'u': 26584,\n",
              "             'h': 51310,\n",
              "             ',': 19846,\n",
              "             'm': 22243,\n",
              "             'k': 7088,\n",
              "             '.': 7885,\n",
              "             'A': 7819,\n",
              "             'l': 33339,\n",
              "             'S': 4523,\n",
              "             'Y': 1718,\n",
              "             'v': 7793,\n",
              "             '?': 2462,\n",
              "             'R': 4869,\n",
              "             'M': 2840,\n",
              "             'W': 3530,\n",
              "             \"'\": 6187,\n",
              "             'L': 3876,\n",
              "             'I': 11832,\n",
              "             'N': 5079,\n",
              "             'g': 13356,\n",
              "             ';': 3628,\n",
              "             'b': 11321,\n",
              "             '!': 2172,\n",
              "             'O': 5481,\n",
              "             'j': 628,\n",
              "             'V': 798,\n",
              "             '-': 1897,\n",
              "             'T': 7015,\n",
              "             'H': 3068,\n",
              "             'E': 6041,\n",
              "             'U': 3313,\n",
              "             'D': 2089,\n",
              "             'P': 1641,\n",
              "             'q': 609,\n",
              "             'x': 529,\n",
              "             'J': 320,\n",
              "             'G': 2399,\n",
              "             'K': 1584,\n",
              "             'Q': 231,\n",
              "             '&': 3,\n",
              "             'Z': 198,\n",
              "             'X': 112,\n",
              "             '3': 27,\n",
              "             '$': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "SAMPLE_SIZE = 500\n",
        "training_data_size = len(raw_training_data)\n",
        "start = random.randrange(0, training_data_size - SAMPLE_SIZE)\n",
        "print(raw_training_data[start:start+SAMPLE_SIZE])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuwEq6IjqmLW",
        "outputId": "ae3035ae-c6f1-4ca7-d50a-69c210115962"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t I name them! Your high self,\n",
            "The gracious mark o' the land, you have obscured\n",
            "With a swain's wearing, and me, poor lowly maid,\n",
            "Most goddess-like prank'd up: but that our feasts\n",
            "In every mess have folly and the feeders\n",
            "Digest it with a custom, I should blush\n",
            "To see you so attired, sworn, I think,\n",
            "To show myself a glass.\n",
            "\n",
            "FLORIZEL:\n",
            "I bless the time\n",
            "When my good falcon made her flight across\n",
            "Thy father's ground.\n",
            "\n",
            "PERDITA:\n",
            "Now Jove afford you cause!\n",
            "To me the difference forges dread; your greatnes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preparation"
      ],
      "metadata": {
        "id": "wD7OFGNXsHmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = ''.join(sorted(set(raw_training_data)))\n",
        "token_to_number = {t: i for i, t in enumerate(tokens)}\n",
        "token_to_number"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGfIhtuKuAlY",
        "outputId": "47604ae7-d6bd-4219-ae25-cf47152ae94a"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '$': 3,\n",
              " '&': 4,\n",
              " \"'\": 5,\n",
              " ',': 6,\n",
              " '-': 7,\n",
              " '.': 8,\n",
              " '3': 9,\n",
              " ':': 10,\n",
              " ';': 11,\n",
              " '?': 12,\n",
              " 'A': 13,\n",
              " 'B': 14,\n",
              " 'C': 15,\n",
              " 'D': 16,\n",
              " 'E': 17,\n",
              " 'F': 18,\n",
              " 'G': 19,\n",
              " 'H': 20,\n",
              " 'I': 21,\n",
              " 'J': 22,\n",
              " 'K': 23,\n",
              " 'L': 24,\n",
              " 'M': 25,\n",
              " 'N': 26,\n",
              " 'O': 27,\n",
              " 'P': 28,\n",
              " 'Q': 29,\n",
              " 'R': 30,\n",
              " 'S': 31,\n",
              " 'T': 32,\n",
              " 'U': 33,\n",
              " 'V': 34,\n",
              " 'W': 35,\n",
              " 'X': 36,\n",
              " 'Y': 37,\n",
              " 'Z': 38,\n",
              " 'a': 39,\n",
              " 'b': 40,\n",
              " 'c': 41,\n",
              " 'd': 42,\n",
              " 'e': 43,\n",
              " 'f': 44,\n",
              " 'g': 45,\n",
              " 'h': 46,\n",
              " 'i': 47,\n",
              " 'j': 48,\n",
              " 'k': 49,\n",
              " 'l': 50,\n",
              " 'm': 51,\n",
              " 'n': 52,\n",
              " 'o': 53,\n",
              " 'p': 54,\n",
              " 'q': 55,\n",
              " 'r': 56,\n",
              " 's': 57,\n",
              " 't': 58,\n",
              " 'u': 59,\n",
              " 'v': 60,\n",
              " 'w': 61,\n",
              " 'x': 62,\n",
              " 'y': 63,\n",
              " 'z': 64}"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "number_to_token = {i: t for i, t in enumerate(tokens)} #mapping each token to its corresponding token\n",
        "number_to_token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9B6mwuCuCYm",
        "outputId": "2d0148df-0a93-44e2-d11e-5e3defef99b4"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '\\n',\n",
              " 1: ' ',\n",
              " 2: '!',\n",
              " 3: '$',\n",
              " 4: '&',\n",
              " 5: \"'\",\n",
              " 6: ',',\n",
              " 7: '-',\n",
              " 8: '.',\n",
              " 9: '3',\n",
              " 10: ':',\n",
              " 11: ';',\n",
              " 12: '?',\n",
              " 13: 'A',\n",
              " 14: 'B',\n",
              " 15: 'C',\n",
              " 16: 'D',\n",
              " 17: 'E',\n",
              " 18: 'F',\n",
              " 19: 'G',\n",
              " 20: 'H',\n",
              " 21: 'I',\n",
              " 22: 'J',\n",
              " 23: 'K',\n",
              " 24: 'L',\n",
              " 25: 'M',\n",
              " 26: 'N',\n",
              " 27: 'O',\n",
              " 28: 'P',\n",
              " 29: 'Q',\n",
              " 30: 'R',\n",
              " 31: 'S',\n",
              " 32: 'T',\n",
              " 33: 'U',\n",
              " 34: 'V',\n",
              " 35: 'W',\n",
              " 36: 'X',\n",
              " 37: 'Y',\n",
              " 38: 'Z',\n",
              " 39: 'a',\n",
              " 40: 'b',\n",
              " 41: 'c',\n",
              " 42: 'd',\n",
              " 43: 'e',\n",
              " 44: 'f',\n",
              " 45: 'g',\n",
              " 46: 'h',\n",
              " 47: 'i',\n",
              " 48: 'j',\n",
              " 49: 'k',\n",
              " 50: 'l',\n",
              " 51: 'm',\n",
              " 52: 'n',\n",
              " 53: 'o',\n",
              " 54: 'p',\n",
              " 55: 'q',\n",
              " 56: 'r',\n",
              " 57: 's',\n",
              " 58: 't',\n",
              " 59: 'u',\n",
              " 60: 'v',\n",
              " 61: 'w',\n",
              " 62: 'x',\n",
              " 63: 'y',\n",
              " 64: 'z'}"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(s):\n",
        "  return_value = []\n",
        "  for character in s:\n",
        "    return_value.append(token_to_number[character])\n",
        "  return return_value\n",
        "encode(\"Tech Exhange\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VGvIoFTwVB8",
        "outputId": "06a60b93-1f0f-4f7e-d550-e7127f2231c9"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[32, 43, 41, 46, 1, 17, 62, 46, 39, 52, 45, 43]"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode(nums):\n",
        "  return ''.join([number_to_token[n] for n in nums ])\n",
        "decode(encode(\"Tech Exchange\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fZ_5rb0Xw1VI",
        "outputId": "acf4df3f-1a8e-4246-e90b-aeb96722cbdc"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tech Exchange'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "data = torch.tensor(encode(raw_training_data), dtype=torch.long)"
      ],
      "metadata": {
        "id": "drZiaCHJxRUz"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "holdout_size = int(0.1 * len(data))\n",
        "holdout_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xopSQOh1xjRo",
        "outputId": "2b22fdff-aa57-418f-bc0d-d269424a8b0f"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "111539"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = data[:holdout_size]\n",
        "training_data = data[holdout_size:]\n",
        "len(test_data), len(training_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-qkBqiOx6Ft",
        "outputId": "3f1c7909-0750-4065-cbe1-f8ae22bb1ca4"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(111539, 1003855)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TzOsirqRvrY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BLOCK_SIZE = 8\n",
        "training_data[:BLOCK_SIZE+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DR0bIIvzyyhR",
        "outputId": "c01c13a1-cbbd-41f7-c9eb-a48ba601da48"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([43, 58,  6,  1, 25, 39, 56, 41, 47])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_from = random.randint(0, training_data_size-BLOCK_SIZE)\n",
        "decode(training_data[start_from:start_from+BLOCK_SIZE].tolist())\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "e_iVneR7y0o9",
        "outputId": "43a681d6-e5ae-4e6e-a5b7-de43ac7ff4f6"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'t such r'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = training_data[:BLOCK_SIZE]\n",
        "y = training_data[1:BLOCK_SIZE+1]\n",
        "for t in range(BLOCK_SIZE):\n",
        "  context = x[:t+1]\n",
        "  target = y[t]\n",
        "  print(f\"in: {context}, out: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vn_FMOMFzq4L",
        "outputId": "f27b075b-0f17-4336-f76d-b9e614e8ed61"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in: tensor([43]), out: 58\n",
            "in: tensor([43, 58]), out: 6\n",
            "in: tensor([43, 58,  6]), out: 1\n",
            "in: tensor([43, 58,  6,  1]), out: 25\n",
            "in: tensor([43, 58,  6,  1, 25]), out: 39\n",
            "in: tensor([43, 58,  6,  1, 25, 39]), out: 56\n",
            "in: tensor([43, 58,  6,  1, 25, 39, 56]), out: 41\n",
            "in: tensor([43, 58,  6,  1, 25, 39, 56, 41]), out: 47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "\n",
        "BATCH_SIZE = 4"
      ],
      "metadata": {
        "id": "ClD9W-sE11mi"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(split):\n",
        "  data = training_data if split == 'train' else test_data\n",
        "  ix = torch.randint(len(data) - BLOCK_SIZE, (BATCH_SIZE,))\n",
        "  #print(ix)\n",
        "  x = torch.stack([data[i:i+BLOCK_SIZE] for i in ix])\n",
        "  y = torch.stack([data[i+1:i+BLOCK_SIZE+1] for i in ix])\n",
        "  return x, y\n",
        "\n",
        "get_batch('train')\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ds5cTSn2pxa",
        "outputId": "baca8ca7-584b-47d2-889c-13c7638ab50e"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[42,  1, 58, 59, 56, 52, 57,  1],\n",
              "         [ 1, 17, 52, 45, 50, 39, 52, 42],\n",
              "         [47, 58, 46,  1, 46, 43, 56,  1],\n",
              "         [ 1, 46, 47, 57,  1, 44, 43, 50]]),\n",
              " tensor([[ 1, 58, 59, 56, 52, 57,  1, 58],\n",
              "         [17, 52, 45, 50, 39, 52, 42,  5],\n",
              "         [58, 46,  1, 46, 43, 56,  1, 58],\n",
              "         [46, 47, 57,  1, 44, 43, 50, 50]]))"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xb, yb = get_batch('train')\n",
        "for b in range(BATCH_SIZE):\n",
        "  for t in range(BLOCK_SIZE):\n",
        "    context = xb[b, :t+1]\n",
        "    target = yb[b,t]\n",
        "    print(f'input {context.tolist()}, target {target}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgpEWsl73obE",
        "outputId": "f1807c8f-382c-4433-b7a1-71943af99248"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input [50], target 47\n",
            "input [50, 47], target 60\n",
            "input [50, 47, 60], target 43\n",
            "input [50, 47, 60, 43], target 42\n",
            "input [50, 47, 60, 43, 42], target 1\n",
            "input [50, 47, 60, 43, 42, 1], target 57\n",
            "input [50, 47, 60, 43, 42, 1, 57], target 53\n",
            "input [50, 47, 60, 43, 42, 1, 57, 53], target 1\n",
            "input [45], target 53\n",
            "input [45, 53], target 53\n",
            "input [45, 53, 53], target 42\n",
            "input [45, 53, 53, 42], target 1\n",
            "input [45, 53, 53, 42, 1], target 39\n",
            "input [45, 53, 53, 42, 1, 39], target 1\n",
            "input [45, 53, 53, 42, 1, 39, 1], target 45\n",
            "input [45, 53, 53, 42, 1, 39, 1, 45], target 47\n",
            "input [47], target 45\n",
            "input [47, 45], target 46\n",
            "input [47, 45, 46], target 58\n",
            "input [47, 45, 46, 58], target 11\n",
            "input [47, 45, 46, 58, 11], target 0\n",
            "input [47, 45, 46, 58, 11, 0], target 14\n",
            "input [47, 45, 46, 58, 11, 0, 14], target 59\n",
            "input [47, 45, 46, 58, 11, 0, 14, 59], target 58\n",
            "input [52], target 1\n",
            "input [52, 1], target 58\n",
            "input [52, 1, 58], target 46\n",
            "input [52, 1, 58, 46], target 63\n",
            "input [52, 1, 58, 46, 63], target 1\n",
            "input [52, 1, 58, 46, 63, 1], target 44\n",
            "input [52, 1, 58, 46, 63, 1, 44], target 39\n",
            "input [52, 1, 58, 46, 63, 1, 44, 39], target 41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "mPnEZnXy4ZHj"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "BLOCK_SIZE = 8\n",
        "LEARNING_RATE = 1e-3\n",
        "MAX_ITERS = 5000\n",
        "EVAL_INTERVAL = 300\n",
        "EVAL_ITERS = 200\n",
        "NUM_EMBEDDINGS = 32\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "aZFiF2G5O8sL"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(set(raw_training_data))\n",
        "class Head(nn.Module):\n",
        "  def __init__(self, head_size):\n",
        "    super().__init__()\n",
        "    self.key = nn.Linear(NUM_EMBEDDINGS, head_size, bias=False)\n",
        "    self.query = nn.Linear(NUM_EMBEDDINGS, head_size, bias=False)\n",
        "    self.value = nn.Linear(NUM_EMBEDDINGS, head_size, bias=False)\n",
        "    self.register_buffer('tril', torch.tril(torch.ones(BLOCK_SIZE, BLOCK_SIZE)))\n",
        "\n",
        "  def forward(self, x):\n",
        "    B,T,C = x.shape\n",
        "    k = self.key(x)\n",
        "    q = self.query(x)\n",
        "    wei = q @ k.transpose(-2, -1) * C**-0.5\n",
        "    wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
        "    wei = F.softmax(wei, dim=-1)\n",
        "    v = self.value(x)\n",
        "    out = wei @ v\n",
        "    return out\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    self.token_embedding_table = nn.Embedding(vocab_size, NUM_EMBEDDINGS)\n",
        "    self.position_embedding_table = nn.Embedding(BLOCK_SIZE, NUM_EMBEDDINGS)\n",
        "    self.lm_head = nn.Linear(NUM_EMBEDDINGS, vocab_size)\n",
        "\n",
        "\n",
        "  def forward(self, token, targets=None):\n",
        "    token_embeddings = self.token_embedding_table(token)\n",
        "    B, T = token.shape\n",
        "    position_embeddings = self.position_embedding_table(torch.arange(T))\n",
        "    x = token_embeddings + position_embeddings\n",
        "\n",
        "    logits = self.lm_head(x)\n",
        "\n",
        "    if targets is None:\n",
        "      loss = None\n",
        "    else:\n",
        "      B, T, C = logits.shape\n",
        "      logits = logits.view(B*T, C)\n",
        "      targets = targets.view(B*T)\n",
        "      loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "    return logits, loss\n",
        "\n",
        "  def generate(self, idx, max_new_tokens):\n",
        "    for _ in range(max_new_tokens):\n",
        "      idx_cond = idx[:, -BLOCK_SIZE:]\n",
        "      logits, loss = self(idx_cond)\n",
        "      logits = logits[:, -1, :] # (B, C)\n",
        "      probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "      idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "      idx = torch.cat((idx, idx_next), dim=1)\n",
        "    return idx\n",
        "\n",
        "m = BigramLanguageModel(vocab_size)\n",
        "z = torch.zeros((1,1), dtype=torch.long)\n",
        "print(decode(m.generate(z, 40)[0].tolist()))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33Tw9qTFFbgW",
        "outputId": "6f83a635-4aad-49a6-cbe9-0b1d71948a3d"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EDHmfr ghU3VU:k$AxlZSyHWWz\n",
            "d;.k!tdKwx;Uj\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "  out = {}\n",
        "  m.eval()\n",
        "  for split in ['train', 'val']:\n",
        "    losses = torch.zeros(EVAL_ITERS)\n",
        "    for k in range(EVAL_ITERS):\n",
        "      X, Y = get_batch(split)\n",
        "      logits, loss = m(X, Y)\n",
        "      losses[k] = loss.item()\n",
        "    out[split] = losses.mean()\n",
        "  m.train()\n",
        "  return out"
      ],
      "metadata": {
        "id": "mrAeHSuXQU1b"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(m.parameters(), lr=1e-3)\n",
        "\n",
        "for iter in range(MAX_ITERS):\n",
        "\n",
        "  if iter % EVAL_INTERVAL == 0:\n",
        "    losses = estimate_loss()\n",
        "    print(f\"iter {iter}; train loss {losses['train']:.4f}; val loss {losses['val']:.4f}\")\n",
        "\n",
        "  xb, yb = get_batch('train')\n",
        "\n",
        "  logits, loss = m(xb, yb)\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QDkjd6PH2Ag",
        "outputId": "931d21c4-2cfb-4bb5-bcc9-8f88467be3df"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter 0; train loss 4.5138; val loss 4.5129\n",
            "iter 300; train loss 2.8876; val loss 2.8793\n",
            "iter 600; train loss 2.6927; val loss 2.6997\n",
            "iter 900; train loss 2.6022; val loss 2.6233\n",
            "iter 1200; train loss 2.5630; val loss 2.5744\n",
            "iter 1500; train loss 2.5317; val loss 2.5522\n",
            "iter 1800; train loss 2.5265; val loss 2.5364\n",
            "iter 2100; train loss 2.5158; val loss 2.5312\n",
            "iter 2400; train loss 2.5127; val loss 2.5298\n",
            "iter 2700; train loss 2.4960; val loss 2.5159\n",
            "iter 3000; train loss 2.4935; val loss 2.5078\n",
            "iter 3300; train loss 2.4948; val loss 2.5082\n",
            "iter 3600; train loss 2.4843; val loss 2.5169\n",
            "iter 3900; train loss 2.4821; val loss 2.5090\n",
            "iter 4200; train loss 2.4824; val loss 2.5161\n",
            "iter 4500; train loss 2.4826; val loss 2.5065\n",
            "iter 4800; train loss 2.4808; val loss 2.4997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.zeros((1,1), dtype=torch.long)\n",
        "generated = m.generate(z, max_new_tokens=100)\n",
        "generated_list = generated[0].tolist()\n",
        "print(decode(generated_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWLjYYLFLc5z",
        "outputId": "48eff2eb-084a-40dc-8883-4334ad10d74f"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "cCH!:cEFG$ Oe'L uRjJ\n",
            "JErqhkr3KzVfKIbPG:Y?ENs'weZDbZ:Ddm$cEQgwp-CYrcTHk MSmWK-vx;MxDamhYbs'rgnwYboe!;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(sorted(set(raw_training_data)))[25]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WYQT9AIBEd-S",
        "outputId": "0ab7a411-7a59-49df-9351-594f34de1f31"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'M'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "-np.log(1/65)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NI9X0lcDFJO",
        "outputId": "fd72f949-dec9-4e8e-a72e-e97fa359405a"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.174387269895637"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kBjKEDtgEnZ2"
      },
      "execution_count": 95,
      "outputs": []
    }
  ]
}